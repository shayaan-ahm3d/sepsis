{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c7bd1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import lgbm_pipeline.feature_load as loader\n",
    "import lgbm_pipeline.feature_extraction as extractor\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score, make_scorer, RocCurveDisplay, ConfusionMatrixDisplay, classification_report\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c5cedf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading PSV Files: 100%|██████████| 20336/20336 [00:26<00:00, 765.61it/s]\n"
     ]
    }
   ],
   "source": [
    "patients: list[pd.DataFrame] = loader.load_training_data(f\"../training_setA/*.psv\")\n",
    "# f = open(\"patients\", \"w\")\n",
    "# pickle.dump(patients, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ecbe82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting indices to timedeltas: 100%|██████████| 20336/20336 [00:03<00:00, 6659.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sepsis patients in training set: 1342\n",
      "Number of non-sepsis patients in training set: 13909\n",
      "Number of patients in training set: 15251\n",
      "\n",
      "Number of sepsis patients in testing set: 448\n",
      "Number of non-sepsis patients in testing set: 4637\n",
      "Number of patients in testing set: 5085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sepsis_patients: list[pd.DataFrame] = []\n",
    "non_sepsis_patients: list[pd.DataFrame] = []\n",
    "\n",
    "for patient in tqdm(patients, \"Converting indices to timedeltas\"):\n",
    "    patient.index = pd.to_timedelta(patient.index, 'h')\n",
    "    if patient[\"SepsisLabel\"].any():\n",
    "        sepsis_patients.append(patient)\n",
    "    else:\n",
    "        non_sepsis_patients.append(patient)\n",
    "\n",
    "train_sepsis_patients, test_sepsis_patients = train_test_split(sepsis_patients)\n",
    "train_non_sepsis_patients, test_non_sepsis_patients = train_test_split(non_sepsis_patients)\n",
    "\n",
    "weight: float = len(train_non_sepsis_patients)/len(train_sepsis_patients)\n",
    "\n",
    "train_patients: list[pd.DataFrame] = train_sepsis_patients + train_non_sepsis_patients\n",
    "test_patients: list[pd.DataFrame] = test_sepsis_patients + test_non_sepsis_patients\n",
    "\n",
    "print(f\"Number of sepsis patients in training set: {len(train_sepsis_patients)}\")\n",
    "print(f\"Number of non-sepsis patients in training set: {len(train_non_sepsis_patients)}\")\n",
    "print(f\"Number of patients in training set: {len(train_patients)}\\n\")\n",
    "print(f\"Number of sepsis patients in testing set: {len(test_sepsis_patients)}\")\n",
    "print(f\"Number of non-sepsis patients in testing set: {len(test_non_sepsis_patients)}\")\n",
    "print(f\"Number of patients in testing set: {len(test_patients)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7820767c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filling gaps in patient data: 100%|██████████| 15251/15251 [00:01<00:00, 8073.56it/s]\n",
      "Filling gaps in patient data: 100%|██████████| 15251/15251 [00:02<00:00, 7390.36it/s]\n",
      "Filling gaps in patient data: 100%|██████████| 15251/15251 [00:20<00:00, 757.62it/s]\n"
     ]
    }
   ],
   "source": [
    "train_patients_forward: list[pd.DataFrame] = extractor.fill(train_patients, extractor.FillMethod.FORWARD)\n",
    "train_patients_backward: list[pd.DataFrame] = extractor.fill(train_patients, extractor.FillMethod.BACKWARD)\n",
    "train_patients_linear: list[pd.DataFrame] = extractor.fill(train_patients, extractor.FillMethod.LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01cc4e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing correlation matrices: 100%|██████████| 3/3 [00:31<00:00, 10.51s/it]\n",
      "100%|██████████| 3/3 [00:00<00:00, 7979.02it/s]0/37 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 19358.33it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 15907.60it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10364.84it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10520.83it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 13827.38it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10313.86it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10556.13it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 9383.23it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 11234.74it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 9144.56it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 6743.25it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10131.17it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 4730.42it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 11904.36it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 9876.70it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 9058.97it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 9218.25it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10636.44it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10672.53it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 9164.54it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3724.96it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 8338.58it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10172.12it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 13981.01it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10238.33it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10459.61it/s]6/37 [00:00<00:00, 254.08it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 11076.51it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 9686.61it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 7410.43it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10913.19it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 9822.73it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 11234.74it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 12421.43it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 9039.45it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10828.67it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 7658.50it/s]\n",
      "Finding optimal fill methods: 100%|██████████| 37/37 [00:00<00:00, 247.82it/s]\n"
     ]
    }
   ],
   "source": [
    "fill_method_to_train_patients: dict[extractor.FillMethod, list[pd.DataFrame]] = {extractor.FillMethod.FORWARD: train_patients_forward,\n",
    "                              extractor.FillMethod.BACKWARD: train_patients_backward,\n",
    "\t\t\t\t\t\t\t  extractor.FillMethod.LINEAR: train_patients_linear}\n",
    "fill_methods_to_use: dict[str, extractor.FillMethod] = extractor.select_best_fill_methods(fill_method_to_train_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7362be54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filling gaps in patient data: 100%|██████████| 5085/5085 [00:00<00:00, 8199.85it/s]\n",
      "Filling gaps in patient data: 100%|██████████| 5085/5085 [00:00<00:00, 9471.91it/s] \n",
      "Filling gaps in patient data: 100%|██████████| 5085/5085 [00:06<00:00, 831.47it/s]\n"
     ]
    }
   ],
   "source": [
    "test_patients_forward: list[pd.DataFrame] = extractor.fill(test_patients, extractor.FillMethod.FORWARD)\n",
    "test_patients_backward: list[pd.DataFrame] = extractor.fill(test_patients, extractor.FillMethod.BACKWARD)\n",
    "test_patients_linear: list[pd.DataFrame] = extractor.fill(test_patients, extractor.FillMethod.LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfa6e4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Doing mixed fill: 100%|██████████| 15251/15251 [01:13<00:00, 207.20it/s]\n",
      "Doing mixed fill: 100%|██████████| 5085/5085 [00:23<00:00, 213.67it/s]\n"
     ]
    }
   ],
   "source": [
    "train_patients_mixed = extractor.mixed_fill(train_patients, train_patients_forward, train_patients_backward, train_patients_linear, fill_methods_to_use)\n",
    "test_patients_mixed = extractor.mixed_fill(test_patients, test_patients_forward, test_patients_backward, test_patients_linear, fill_methods_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed0ebdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extending indices and splitting into (X_train, y_train): 100%|██████████| 15251/15251 [00:43<00:00, 354.28it/s]\n",
      "Extending indices and splitting into (X_test, y_test): 100%|██████████| 5085/5085 [00:17<00:00, 292.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# Find the maximum length of the DataFrames in train_patients_mixed\n",
    "max_length = max(len(df) for df in train_patients_mixed)\n",
    "\n",
    "# Adjust the length of each DataFrame in X_train to match the maximum length and forward-fill missing values\n",
    "X_train: list[pd.DataFrame] = []\n",
    "y_train: list[pd.Series] = []\n",
    "\n",
    "for j in tqdm(range(len(train_patients_mixed)), \"Extending indices and splitting into (X_train, y_train)\"):\n",
    "    df = train_patients_mixed[j]\n",
    "    # Generate a new index that extends to the maximum length\n",
    "    new_index = pd.timedelta_range(start=df.index[0], periods=max_length, freq='h')\n",
    "    df = df.reindex(new_index).ffill()  # Reindex to the new index and forward-fill\n",
    "    X_train.append(df.drop(columns=\"SepsisLabel\", inplace=False))\n",
    "    y_train.append(df[\"SepsisLabel\"])\n",
    "\n",
    "# Adjust the length of each DataFrame in X_test similarly\n",
    "X_test: list[pd.DataFrame] = []\n",
    "y_test: list[pd.Series] = []\n",
    "\n",
    "for k in tqdm(range(len(test_patients_mixed)), \"Extending indices and splitting into (X_test, y_test)\"):\n",
    "    df = test_patients_mixed[k]\n",
    "    new_index = pd.timedelta_range(start=df.index[0], periods=max_length, freq='h')\n",
    "    df = df.reindex(new_index).ffill()\n",
    "    X_test.append(df.drop(columns=\"SepsisLabel\", inplace=False))\n",
    "    y_test.append(df[\"SepsisLabel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93333c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdbe5cfd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please reshape the input data into 2-dimensional matrix.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m f \u001b[38;5;241m=\u001b[39m make_scorer(fbeta_score, beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m clf \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary:logistic\u001b[39m\u001b[38;5;124m\"\u001b[39m, eval_metric\u001b[38;5;241m=\u001b[39mf, scale_pos_weight\u001b[38;5;241m=\u001b[39mweight)\n\u001b[0;32m----> 4\u001b[0m bst \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/anaconda3/envs/AppliedDataScience/lib/python3.12/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/AppliedDataScience/lib/python3.12/site-packages/xgboost/sklearn.py:1512\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_class\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_\n\u001b[1;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[0;32m-> 1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1513\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1514\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   1515\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m   1516\u001b[0m     group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1517\u001b[0m     qid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1518\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1519\u001b[0m     base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[1;32m   1520\u001b[0m     feature_weights\u001b[38;5;241m=\u001b[39mfeature_weights,\n\u001b[1;32m   1521\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39meval_set,\n\u001b[1;32m   1522\u001b[0m     sample_weight_eval_set\u001b[38;5;241m=\u001b[39msample_weight_eval_set,\n\u001b[1;32m   1523\u001b[0m     base_margin_eval_set\u001b[38;5;241m=\u001b[39mbase_margin_eval_set,\n\u001b[1;32m   1524\u001b[0m     eval_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1525\u001b[0m     eval_qid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1526\u001b[0m     create_dmatrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_dmatrix,\n\u001b[1;32m   1527\u001b[0m     enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_categorical,\n\u001b[1;32m   1528\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1529\u001b[0m )\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m   1532\u001b[0m     params,\n\u001b[1;32m   1533\u001b[0m     train_dmatrix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1542\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[1;32m   1543\u001b[0m )\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "File \u001b[0;32m~/anaconda3/envs/AppliedDataScience/lib/python3.12/site-packages/xgboost/sklearn.py:596\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_evaluation_matrices\u001b[39m(\n\u001b[1;32m    577\u001b[0m     missing: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[1;32m    578\u001b[0m     X: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    592\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[1;32m    593\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m    way.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 596\u001b[0m     train_dmatrix \u001b[38;5;241m=\u001b[39m create_dmatrix(\n\u001b[1;32m    597\u001b[0m         data\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    598\u001b[0m         label\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    599\u001b[0m         group\u001b[38;5;241m=\u001b[39mgroup,\n\u001b[1;32m    600\u001b[0m         qid\u001b[38;5;241m=\u001b[39mqid,\n\u001b[1;32m    601\u001b[0m         weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    602\u001b[0m         base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[1;32m    603\u001b[0m         feature_weights\u001b[38;5;241m=\u001b[39mfeature_weights,\n\u001b[1;32m    604\u001b[0m         missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[1;32m    605\u001b[0m         enable_categorical\u001b[38;5;241m=\u001b[39menable_categorical,\n\u001b[1;32m    606\u001b[0m         feature_types\u001b[38;5;241m=\u001b[39mfeature_types,\n\u001b[1;32m    607\u001b[0m         ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    608\u001b[0m     )\n\u001b[1;32m    610\u001b[0m     n_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(eval_set)\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence:\n",
      "File \u001b[0;32m~/anaconda3/envs/AppliedDataScience/lib/python3.12/site-packages/xgboost/sklearn.py:1003\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[0;34m(self, ref, **kwargs)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _can_use_qdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_method) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbooster \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1003\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m QuantileDMatrix(\n\u001b[1;32m   1004\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, ref\u001b[38;5;241m=\u001b[39mref, nthread\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, max_bin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_bin\n\u001b[1;32m   1005\u001b[0m         )\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/AppliedDataScience/lib/python3.12/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/AppliedDataScience/lib/python3.12/site-packages/xgboost/core.py:1573\u001b[0m, in \u001b[0;36mQuantileDMatrix.__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[1;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m   1554\u001b[0m         info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1555\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m         )\n\u001b[1;32m   1567\u001b[0m     ):\n\u001b[1;32m   1568\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1569\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf data iterator is used as input, data like label should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1570\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified as batch argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1571\u001b[0m         )\n\u001b[0;32m-> 1573\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init(\n\u001b[1;32m   1574\u001b[0m     data,\n\u001b[1;32m   1575\u001b[0m     ref\u001b[38;5;241m=\u001b[39mref,\n\u001b[1;32m   1576\u001b[0m     label\u001b[38;5;241m=\u001b[39mlabel,\n\u001b[1;32m   1577\u001b[0m     weight\u001b[38;5;241m=\u001b[39mweight,\n\u001b[1;32m   1578\u001b[0m     base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[1;32m   1579\u001b[0m     group\u001b[38;5;241m=\u001b[39mgroup,\n\u001b[1;32m   1580\u001b[0m     qid\u001b[38;5;241m=\u001b[39mqid,\n\u001b[1;32m   1581\u001b[0m     label_lower_bound\u001b[38;5;241m=\u001b[39mlabel_lower_bound,\n\u001b[1;32m   1582\u001b[0m     label_upper_bound\u001b[38;5;241m=\u001b[39mlabel_upper_bound,\n\u001b[1;32m   1583\u001b[0m     feature_weights\u001b[38;5;241m=\u001b[39mfeature_weights,\n\u001b[1;32m   1584\u001b[0m     feature_names\u001b[38;5;241m=\u001b[39mfeature_names,\n\u001b[1;32m   1585\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39mfeature_types,\n\u001b[1;32m   1586\u001b[0m     enable_categorical\u001b[38;5;241m=\u001b[39menable_categorical,\n\u001b[1;32m   1587\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/AppliedDataScience/lib/python3.12/site-packages/xgboost/core.py:1632\u001b[0m, in \u001b[0;36mQuantileDMatrix._init\u001b[0;34m(self, data, ref, enable_categorical, **meta)\u001b[0m\n\u001b[1;32m   1620\u001b[0m config \u001b[38;5;241m=\u001b[39m make_jcargs(\n\u001b[1;32m   1621\u001b[0m     nthread\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnthread, missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing, max_bin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_bin\n\u001b[1;32m   1622\u001b[0m )\n\u001b[1;32m   1623\u001b[0m ret \u001b[38;5;241m=\u001b[39m _LIB\u001b[38;5;241m.\u001b[39mXGQuantileDMatrixCreateFromCallback(\n\u001b[1;32m   1624\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1625\u001b[0m     it\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1630\u001b[0m     ctypes\u001b[38;5;241m.\u001b[39mbyref(handle),\n\u001b[1;32m   1631\u001b[0m )\n\u001b[0;32m-> 1632\u001b[0m it\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[1;32m   1633\u001b[0m \u001b[38;5;66;03m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[1;32m   1634\u001b[0m _check_call(ret)\n",
      "File \u001b[0;32m~/anaconda3/envs/AppliedDataScience/lib/python3.12/site-packages/xgboost/core.py:569\u001b[0m, in \u001b[0;36mDataIter.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    567\u001b[0m exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/anaconda3/envs/AppliedDataScience/lib/python3.12/site-packages/xgboost/core.py:550\u001b[0m, in \u001b[0;36mDataIter._handle_exception\u001b[0;34m(self, fn, dft_ret)\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dft_ret\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn()\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;66;03m# Defer the exception in order to return 0 and stop the iteration.\u001b[39;00m\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;66;03m# Exception inside a ctype callback function has no effect except\u001b[39;00m\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;66;03m# for printing to stderr (doesn't stop the execution).\u001b[39;00m\n\u001b[1;32m    555\u001b[0m     tb \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/AppliedDataScience/lib/python3.12/site-packages/xgboost/core.py:637\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_temporary_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_exception(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext(input_data), \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/AppliedDataScience/lib/python3.12/site-packages/xgboost/data.py:1416\u001b[0m, in \u001b[0;36mSingleBatchInternalIter.next\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m   1414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mit \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1416\u001b[0m input_data(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/AppliedDataScience/lib/python3.12/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/AppliedDataScience/lib/python3.12/site-packages/xgboost/core.py:625\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.input_data\u001b[0;34m(data, feature_names, feature_types, **kwargs)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;66;03m# Stage the data, meta info are copied inside C++ MetaInfo.\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_temporary_data \u001b[38;5;241m=\u001b[39m (new, cat_codes, feature_names, feature_types)\n\u001b[0;32m--> 625\u001b[0m dispatch_proxy_set_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxy, new, cat_codes)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mset_info(\n\u001b[1;32m    627\u001b[0m     feature_names\u001b[38;5;241m=\u001b[39mfeature_names,\n\u001b[1;32m    628\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39mfeature_types,\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    630\u001b[0m )\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_ref \u001b[38;5;241m=\u001b[39m ref\n",
      "File \u001b[0;32m~/anaconda3/envs/AppliedDataScience/lib/python3.12/site-packages/xgboost/data.py:1473\u001b[0m, in \u001b[0;36mdispatch_proxy_set_data\u001b[0;34m(proxy, data, cat_codes)\u001b[0m\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Dispatch for QuantileDMatrix.\"\"\"\u001b[39;00m\n\u001b[1;32m   1472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_cudf_ser(data) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_pandas_series(data):\n\u001b[0;32m-> 1473\u001b[0m     _check_data_shape(data)\n\u001b[1;32m   1475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_cudf_df(data):\n\u001b[1;32m   1476\u001b[0m     \u001b[38;5;66;03m# pylint: disable=W0212\u001b[39;00m\n\u001b[1;32m   1477\u001b[0m     proxy\u001b[38;5;241m.\u001b[39m_ref_data_from_cuda_columnar(data, cast(List, cat_codes))\n",
      "File \u001b[0;32m~/anaconda3/envs/AppliedDataScience/lib/python3.12/site-packages/xgboost/data.py:58\u001b[0m, in \u001b[0;36m_check_data_shape\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_data_shape\u001b[39m(data: DataType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 58\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease reshape the input data into 2-dimensional matrix.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Please reshape the input data into 2-dimensional matrix."
     ]
    }
   ],
   "source": [
    "f = make_scorer(fbeta_score, beta=1)\n",
    "\n",
    "clf = xgb.XGBClassifier(objective=\"binary:logistic\", eval_metric=f, scale_pos_weight=weight)\n",
    "bst = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860673e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bst.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4e2cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_predictions(y_test, y_pred)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AppliedDataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
